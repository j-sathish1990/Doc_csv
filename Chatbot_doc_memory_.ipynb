{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference : https://arxiv.org/pdf/2305.17306.pdf"
      ],
      "metadata": {
        "id": "wxq1jv4p0aSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai langchain chromadb tiktoken pypdf unstructured\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjDCxS3Ngi-8",
        "outputId": "b3bfc8b8-2f17-4dba-8b92-7c1a59c8c6d0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.198)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.3.26)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.8)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.8)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.6.2)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.97.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.2.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.15.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: argilla in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.9.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.2)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured) (20221105)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unstructured) (8.4.0)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.11)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.11)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.21)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.8.10)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: httpx<0.24,>=0.15 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.23.3)\n",
            "Requirement already satisfied: deprecated~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.2.14)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: rich<=13.0.1 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (13.0.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla->unstructured) (0.7.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from msg-parser->unstructured) (0.46)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.2.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured) (40.0.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx->unstructured) (3.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured) (1.15.1)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV5BrAmMhOnT",
        "outputId": "9776a94e-ca63-4a14-fcd2-c6de7c6896ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "u3cmdWYxgG7X"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.vectorstores import Chroma\n",
        "import os\n",
        "openai_api_key = \"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\"\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_loader = UnstructuredWordDocumentLoader(\"Chain_of_thought.docx\")\n",
        "documents = doc_loader.load()"
      ],
      "metadata": {
        "id": "SIiOsr05gglo"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character Text Splitter and embeddings"
      ],
      "metadata": {
        "id": "yEyirBEPvXwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)\n",
        "documents = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "phlilON_vW2-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)"
      ],
      "metadata": {
        "id": "bFGjIJ01mr77"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Memory"
      ],
      "metadata": {
        "id": "biBsrm3IncMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)"
      ],
      "metadata": {
        "id": "vwQzm3VVnVve"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature = 0), vectorstore.as_retriever(),  memory = memory)"
      ],
      "metadata": {
        "id": "V27wvXM7npM3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the document about?\"\n",
        "response = qa({\"question\": query})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Y4lqdBK2olJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03a8b26-a0bd-48cb-d51b-73e35e289ba8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'What is the document about?', 'chat_history': [HumanMessage(lc_kwargs={'content': 'What is the document about?'}, content='What is the document about?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'}, content=' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.', additional_kwargs={}, example=False)], 'answer': ' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EY_ikQdwfys",
        "outputId": "e762195e-f62f-4bf6-9c32-f9a130b668d3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'What is the document about?', 'chat_history': [HumanMessage(lc_kwargs={'content': 'What is the document about?'}, content='What is the document about?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'}, content=' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.', additional_kwargs={}, example=False)], 'answer': ' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qf7yv7eFxPS5",
        "outputId": "80c119a3-a9de-4221-a658-21af44296409"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the key differences between GPT 3.5 and GPT 4 based on the information provided in this document?\"\n",
        "response = qa({\"question\": query})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hX8n6npxS9p",
        "outputId": "3733db6f-5aab-4da7-9977-e24eb723644a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'What are the key differences between GPT 3.5 and GPT 4 based on the information provided in this document?', 'chat_history': [HumanMessage(lc_kwargs={'content': 'What is the document about?'}, content='What is the document about?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'}, content=' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.', additional_kwargs={}, example=False), HumanMessage(lc_kwargs={'content': 'What are the key differences between GPT 3.5 and GPT 4?'}, content='What are the key differences between GPT 3.5 and GPT 4?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' GPT-4 is larger than GPT-3.5 and has more parameters, which allows it to perform more complex tasks. GPT-4 also has a better understanding of natural language and can better handle tasks that require composition of linguistic and logical operations. Additionally, GPT-4 has been trained on more data than GPT-3.5.'}, content=' GPT-4 is larger than GPT-3.5 and has more parameters, which allows it to perform more complex tasks. GPT-4 also has a better understanding of natural language and can better handle tasks that require composition of linguistic and logical operations. Additionally, GPT-4 has been trained on more data than GPT-3.5.', additional_kwargs={}, example=False), HumanMessage(lc_kwargs={'content': 'What are the key differences between GPT 3.5 and GPT 4 based on the information provided in this document?'}, content='What are the key differences between GPT 3.5 and GPT 4 based on the information provided in this document?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' GPT-3.5 and GPT-4 differ in size, parameters, natural language understanding, and data used for training. GPT-3.5 is a smaller model with fewer parameters than GPT-4. GPT-3.5 is trained on a smaller dataset than GPT-4, and is less capable of understanding natural language. GPT-4 is trained on a larger dataset and is more capable of understanding natural language.'}, content=' GPT-3.5 and GPT-4 differ in size, parameters, natural language understanding, and data used for training. GPT-3.5 is a smaller model with fewer parameters than GPT-4. GPT-3.5 is trained on a smaller dataset than GPT-4, and is less capable of understanding natural language. GPT-4 is trained on a larger dataset and is more capable of understanding natural language.', additional_kwargs={}, example=False)], 'answer': ' GPT-3.5 and GPT-4 differ in size, parameters, natural language understanding, and data used for training. GPT-3.5 is a smaller model with fewer parameters than GPT-4. GPT-3.5 is trained on a smaller dataset than GPT-4, and is less capable of understanding natural language. GPT-4 is trained on a larger dataset and is more capable of understanding natural language.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "orjMA2i2ylRW",
        "outputId": "e8c8e184-2df3-42af-8c6e-6b2e9ddd1c76"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' GPT-3.5 and GPT-4 differ in size, parameters, natural language understanding, and data used for training. GPT-3.5 is a smaller model with fewer parameters than GPT-4. GPT-3.5 is trained on a smaller dataset than GPT-4, and is less capable of understanding natural language. GPT-4 is trained on a larger dataset and is more capable of understanding natural language.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the key distinctions between few-shot and zero-shot prompting? \"\n",
        "response = qa({\"question\": query})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaIt1qrJyrlv",
        "outputId": "b06f8890-aa45-4f0e-c3b0-117825cfb036"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'What are the key distinctions between few-shot and zero-shot prompting? ', 'chat_history': [HumanMessage(lc_kwargs={'content': 'What is the document about?'}, content='What is the document about?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.'}, content=' The document is about the development of open-source large language models and an evaluation platform to track the progress of these models.', additional_kwargs={}, example=False), HumanMessage(lc_kwargs={'content': 'What are the key differences between GPT 3.5 and GPT 4?'}, content='What are the key differences between GPT 3.5 and GPT 4?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' GPT-4 is larger than GPT-3.5 and has more parameters, which allows it to perform more complex tasks. GPT-4 also has a better understanding of natural language and can better handle tasks that require composition of linguistic and logical operations. Additionally, GPT-4 has been trained on more data than GPT-3.5.'}, content=' GPT-4 is larger than GPT-3.5 and has more parameters, which allows it to perform more complex tasks. GPT-4 also has a better understanding of natural language and can better handle tasks that require composition of linguistic and logical operations. Additionally, GPT-4 has been trained on more data than GPT-3.5.', additional_kwargs={}, example=False), HumanMessage(lc_kwargs={'content': 'What are the key differences between GPT 3.5 and GPT 4 based on the information provided in this document?'}, content='What are the key differences between GPT 3.5 and GPT 4 based on the information provided in this document?', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' GPT-3.5 and GPT-4 differ in size, parameters, natural language understanding, and data used for training. GPT-3.5 is a smaller model with fewer parameters than GPT-4. GPT-3.5 is trained on a smaller dataset than GPT-4, and is less capable of understanding natural language. GPT-4 is trained on a larger dataset and is more capable of understanding natural language.'}, content=' GPT-3.5 and GPT-4 differ in size, parameters, natural language understanding, and data used for training. GPT-3.5 is a smaller model with fewer parameters than GPT-4. GPT-3.5 is trained on a smaller dataset than GPT-4, and is less capable of understanding natural language. GPT-4 is trained on a larger dataset and is more capable of understanding natural language.', additional_kwargs={}, example=False), HumanMessage(lc_kwargs={'content': 'What are the key distinctions between few-shot and zero-shot prompting? '}, content='What are the key distinctions between few-shot and zero-shot prompting? ', additional_kwargs={}, example=False), AIMessage(lc_kwargs={'content': ' Few-shot prompting is used to evaluate large language models (LLMs) and is a capability that exists in both pretrained and instruction-tuned checkpoints. Zero-shot prompting is more suitable for instruction-tuned checkpoints and may under-estimate the pretrained checkpoints.'}, content=' Few-shot prompting is used to evaluate large language models (LLMs) and is a capability that exists in both pretrained and instruction-tuned checkpoints. Zero-shot prompting is more suitable for instruction-tuned checkpoints and may under-estimate the pretrained checkpoints.', additional_kwargs={}, example=False)], 'answer': ' Few-shot prompting is used to evaluate large language models (LLMs) and is a capability that exists in both pretrained and instruction-tuned checkpoints. Zero-shot prompting is more suitable for instruction-tuned checkpoints and may under-estimate the pretrained checkpoints.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rqa9xaQLzjdM",
        "outputId": "b49e1ad6-f74b-4eab-b86b-2192682722f1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Few-shot prompting is used to evaluate large language models (LLMs) and is a capability that exists in both pretrained and instruction-tuned checkpoints. Zero-shot prompting is more suitable for instruction-tuned checkpoints and may under-estimate the pretrained checkpoints.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CA6-xrCEzkQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
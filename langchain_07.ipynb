{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCayY0fja4FY",
        "outputId": "3c25d7fc-d381-430e-c621-d33bbb11afc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.225)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.9)\n",
            "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.20)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFw-cGrSY-fi",
        "outputId": "756d313e-6052-4e52-c871-70c3a51280ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "import os\n",
        "\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "S43SKbfwizay"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "import os\n",
        "\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPUZgpQJlWfM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "7UuyO9zSZxq4"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model = \"gpt-3.5-turbo\"):\n",
        "  messages = [{\"role\":\"user\", \"content\":prompt}]\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature = 0,\n",
        "  )\n",
        "  return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"What is the largest city in South India?\")"
      ],
      "metadata": {
        "id": "ONDYJpR8y55r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7d10dbff-2e94-4553-dd74-49cac962138d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The largest city in South India is Chennai, the capital of the state of Tamil Nadu.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = \" right now matey! before the kitchen smells funny, lets do the clean up also the kitchen counter.\""
      ],
      "metadata": {
        "id": "0HD_XAgLK4PC"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style = \"Calm and Respectful tone\"\n",
        "prompt = f\"\"\" Translate the text \\\n",
        "that is delimited by triple backticks  into a style  which is {style} \\\n",
        ": --- {email}---\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "WyQ50cZ6QfTh"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAsYV2MpQ66u",
        "outputId": "0a34cb17-9d19-4449-c3e1-fb8a951e4242"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Translate the text that is delimited by triple backticks  into a style  which is Calm and Respectful tone : ---  right now matey! before the kitchen smells funny, lets do the clean up also the kitchen counter.---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_completion(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgzEZ9jbQ-AZ",
        "outputId": "ecbe6177-656a-4e1f-fe18-a3dd992750b1"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right now, my friend, let's take a moment to tidy up the kitchen before any unpleasant odors arise. It would be greatly appreciated if we could also clean the kitchen counter. Thank you for your cooperation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "chat = ChatOpenAI(temperature = 0.2)\n",
        "chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MOsxRBeRGh6",
        "outputId": "94358ce1-8aeb-4939-d7ad-22a968a34973"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.2, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\" Translate the text \\\n",
        "delimited within three backticks  \\\n",
        "into a style which is {style}\n",
        "text : ```{text}```\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "BPqF-lQDRaow"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "prompt_template.messages[0].prompt.input_variables # input variables\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    style = style,\n",
        "    text = email\n",
        ")\n"
      ],
      "metadata": {
        "id": "SJNa36dcUb-R"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(messages)"
      ],
      "metadata": {
        "id": "ZK5Ka205VrY4"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAUi9UFW1Ea",
        "outputId": "e083a02a-4578-4e2d-db10-98aaa12b4abc"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Right now, my friend, let's take a moment to tidy up the kitchen and the kitchen counter before any unpleasant odors arise.\" additional_kwargs={} example=False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pi1ak8MbW4HO",
        "outputId": "f8a6fb48-2b59-4445-eed9-022abaf094fc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Right now, my friend, let's take a moment to tidy up the kitchen and the kitchen counter before any unpleasant odors arise.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_reply = \"\"\" Don't be harsh with your comments matey!. We are humans as well and don't call us a cheat OK?\"\"\"\n"
      ],
      "metadata": {
        "id": "DqOgFy1gXIBU"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style = \"\"\" Please translate to plain and polite and gentle English \"\"\"\n"
      ],
      "metadata": {
        "id": "G3DMYw1oZV94"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\" Translate the text \\\n",
        "delimited within three backticks  \\\n",
        "into a style which is {style}\n",
        "text : ``` {text} ``` \"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGhFQZbNbT-7"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n"
      ],
      "metadata": {
        "id": "0wwPGzffcE3T"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "prompt_template.messages[0].prompt.input_variables # input variables\n",
        "\n",
        "messages = prompt_template.format_messages(\n",
        "    style = style,\n",
        "    text = service_reply\n",
        ")\n"
      ],
      "metadata": {
        "id": "rk7HBH8zcGQI"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat(messages)\n"
      ],
      "metadata": {
        "id": "9D5FBHOncLh1"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ltXAfwvdeU7N",
        "outputId": "283592e7-190e-4f31-9f3c-289c374883d4"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Please refrain from using harsh language in your comments, my friend. We are all human beings, so let's avoid labeling each other as cheaters, alright?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parser to output in a specific format\n",
        "{\n",
        "    \"gift\": False,\n",
        "    \"delivery_days\": 5,\n",
        "    \"price_value\": \"clean and affordable\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3QVqDLIeV2D",
        "outputId": "42331a5f-53ae-439b-a89d-ac4fc9f97aa2"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': False, 'delivery_days': 5, 'price_value': 'clean and affordable'}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"\"\" \\\n",
        "I am so incredibly impressed with this little tool! \\\n",
        "I am a small stature female and for 30 years \\\n",
        "I bought this as a gift for my husband for our anniversary\\\n",
        "one which  wouldn't require super power strength to use. This is it. !!\\\n",
        "Let me say that you WILL need to be realistic regarding power that a 20v battery blower is going to\n",
        "give.\\\n",
        "This is certainly not designed for big jobs and you probably won't see the landscape guys with one. HOWEVER,\\\n",
        "if you need a lightweight, small job blower for the price paid, this is fabulous!\n",
        "and the good part, I was able to receive it in 2 days\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "IJx5MY17i3ip"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_template = \"\"\" \\\n",
        "For the following text, extract the following information :\n",
        "\n",
        "gift: Was the item a gift?\n",
        "receive_days : How many days did it take for the product to be received?\n",
        "price_value : Extract any sentences about the value or price\n",
        "\n",
        "Format the output as a JSON format with the following keys:\n",
        "\n",
        "gift\n",
        "receive_date\n",
        "price_value\n",
        "\n",
        "text : {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GC-LVcocjQLm"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC0mUAHHkAPS",
        "outputId": "8352b09e-a1ad-41d0-b91e-0578a266c23e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template=' For the following text, extract the following information :\\n\\ngift: Was the item a gift?\\nreceive_days : How many days did it take for the product to be received?\\nprice_value : Extract any sentences about the value or price \\n\\nFormat the output as a JSON format with the following keys:\\n\\ngift\\nreceive_date\\nprice_value\\n\\ntext : {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = prompt_template.format_messages(text = review )\n",
        "chat = ChatOpenAI(temperature = 0.1)\n",
        "response = chat(messages)\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEZ04jBLmJWy",
        "outputId": "ee6f1546-f541-4777-f529-a647ac6af165"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"gift\": \"yes\",\n",
            "  \"receive_days\": 2,\n",
            "  \"price_value\": \"small job blower for the price paid\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOcjOZ_1mccM"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "ttHEcSVud5mR"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI()\n",
        "memory = ConversationBufferMemory(k = 1)\n",
        "conversation = ConversationChain(llm = llm,\n",
        "                                 memory = memory,\n",
        "                                 verbose = True)"
      ],
      "metadata": {
        "id": "ZCxk1Kk6d5or"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = \"Hello, my name is Sathish \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "sZl6VTXRhqHX",
        "outputId": "99694550-fadb-44b9-aa66-2a0c8ddbd7df"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hello, my name is Sathish \n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Sathish! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = \"What is artificial intelligence in one sentence?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "lvN85lzPhwIm",
        "outputId": "93cc6234-e8f7-458a-bb75-ab7f8cdf8c86"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, my name is Sathish \n",
            "AI: Hello Sathish! How can I assist you today?\n",
            "Human: What is artificial intelligence in one sentence?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence refers to the development of computer systems that are capable of performing tasks that would typically require human intelligence, such as learning, problem-solving, and decision-making.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = \"What is my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "-VZAFo6oh5gi",
        "outputId": "8a168ebe-12c6-48bd-a89b-5dbcd18d642f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, my name is Sathish \n",
            "AI: Hello Sathish! How can I assist you today?\n",
            "Human: What is artificial intelligence in one sentence?\n",
            "AI: Artificial intelligence refers to the development of computer systems that are capable of performing tasks that would typically require human intelligence, such as learning, problem-solving, and decision-making.\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Sathish.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3wWulJQiarS",
        "outputId": "fdb65a16-3181-477a-b7a3-08d9454f7758"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Hello, my name is Sathish \n",
            "AI: Hello Sathish! How can I assist you today?\n",
            "Human: What is artificial intelligence in one sentence?\n",
            "AI: Artificial intelligence refers to the development of computer systems that are capable of performing tasks that would typically require human intelligence, such as learning, problem-solving, and decision-making.\n",
            "Human: What is my name?\n",
            "AI: Your name is Sathish.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lejPvdvfiF9y",
        "outputId": "257a2728-232b-4aaf-d324-98e8bd344016"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'Human: Hello, my name is Sathish \\nAI: Hello Sathish! How can I assist you today?\\nHuman: What is artificial intelligence in one sentence?\\nAI: Artificial intelligence refers to the development of computer systems that are capable of performing tasks that would typically require human intelligence, such as learning, problem-solving, and decision-making.\\nHuman: What is my name?\\nAI: Your name is Sathish.'}"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context({\"input\":\"Just the usual\"},\n",
        "                    {\"output\": \"alright\"})"
      ],
      "metadata": {
        "id": "N9FdDEsGilGB"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuhbXmifjMqU",
        "outputId": "398f4142-94a1-42a2-cd9a-5e0163f90aab"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'Human: Hello, my name is Sathish \\nAI: Hello Sathish! How can I assist you today?\\nHuman: What is artificial intelligence in one sentence?\\nAI: Artificial intelligence refers to the development of computer systems that are capable of performing tasks that would typically require human intelligence, such as learning, problem-solving, and decision-making.\\nHuman: What is my name?\\nAI: Your name is Sathish.\\nHuman: Just the usual\\nAI: alright'}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ConversationTokenBufferMemory"
      ],
      "metadata": {
        "id": "wtAF_vK5jU1s"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3iLzS66lpP1",
        "outputId": "456d71bf-0d88-47da-837d-bf5199d96ddb"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(temperature = 0.1)\n"
      ],
      "metadata": {
        "id": "hp0JsyhelpSM"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationTokenBufferMemory(llm = llm, max_token_limit=250)\n",
        "memory.save_context({\"input\":\"AI is what?\"},\n",
        "                    {\"output\":\"Great\"})\n",
        "memory.save_context({\"input\":\"Backpropogation is?\"},\n",
        "                    {\"output\":\"beautiful\"})\n",
        "memory.save_context({\"input\":\"Chatbots are what?\"},\n",
        "                    {\"output\":\"intelligent\"})"
      ],
      "metadata": {
        "id": "iwdwB5NJlpUi"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ConversationSummaryMemory\n",
        "\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "\n",
        "story = \"The Ramayana is an ancient Sanskrit epic which follows Prince Rama's \\\n",
        "quest to rescue his beloved wife Sita from the clutches of Ravana with the help of an army of monkeys. \\\n",
        "It is traditionally attributed to the authorship of the \\\n",
        "sage Valmiki and dated to around 500 BCE to 100 BCE.\"\n",
        "\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(llm = llm, memory = memory, verbose = True)\n",
        "memory.save_context({\"input\":\"Hello\"},\n",
        "                    {\"output\":\"nice to meet you\"})\n",
        "memory.save_context({\"input\":\"AI is wonderful\"},\n",
        "                    {\"output\":\"and is creative\"})\n",
        "memory.save_context({\"input\":\"Story telling is an art\"},\n",
        "                    {\"input\":\"So true\"})\n",
        "memory.save_context({\"input\":\"What is the story of Ramayana?\"},\n",
        "                    {\"output\":f\"{story}\"})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vNSqv3x2mpUf"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})\n",
        "conversation = ConversationChain(\n",
        "    llm = llm,\n",
        "    memory = memory,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "HUgGbu9Oq5Ru"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input = \"When was the Ramayana written?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "2yz4xszNrpFt",
        "outputId": "a0c5c5ac-04f1-4866-b2cf-ff869ae48897"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello\n",
            "AI: nice to meet you\n",
            "Human: AI is wonderful\n",
            "AI: and is creative\n",
            "Human: Story telling is an art\n",
            "AI: So true\n",
            "Human: What is the story of Ramayana?\n",
            "AI: The Ramayana is an ancient Sanskrit epic which follows Prince Rama's quest to rescue his beloved wife Sita from the clutches of Ravana with the help of an army of monkeys. It is traditionally attributed to the authorship of the sage Valmiki and dated to around 500 BCE to 100 BCE.\n",
            "Human: When was the Ramayana written?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Ramayana is traditionally attributed to the authorship of the sage Valmiki and is believed to have been written around 500 BCE to 100 BCE.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjjLXy3or8LX",
        "outputId": "d8961b51-6b33-4006-c038-441a0a478e2b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: Hello\\nAI: nice to meet you\\nHuman: AI is wonderful\\nAI: and is creative\\nHuman: Story telling is an art\\nAI: So true\\nHuman: What is the story of Ramayana?\\nAI: The Ramayana is an ancient Sanskrit epic which follows Prince Rama's quest to rescue his beloved wife Sita from the clutches of Ravana with the help of an army of monkeys. It is traditionally attributed to the authorship of the sage Valmiki and dated to around 500 BCE to 100 BCE.\\nHuman: When was the Ramayana written?\\nAI: The Ramayana is traditionally attributed to the authorship of the sage Valmiki and is believed to have been written around 500 BCE to 100 BCE.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8EowWDgsCyP"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRRgFG8e28LQ"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmRHLeB528Nv"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yTA4nl0S28QG"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "Tam5GJ3R28Su"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'books_new.csv'\n",
        "loader = CSVLoader(file_path = file)\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"books_new.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "945_lHzN33-t",
        "outputId": "03f26623-54dd-4586-8d23-1fcda75b6349"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Title            Author       Genre           SubGenre  \\\n",
              "0  Fundamentals of Wavelets  Goswami, Jaideva        tech  signal_processing   \n",
              "1                Data Smart     Foreman, John        tech       data_science   \n",
              "2  God Created the Integers  Hawking, Stephen        tech        mathematics   \n",
              "3         Superfreakonomics   Dubner, Stephen     science          economics   \n",
              "4               Orientalism      Said, Edward  nonfiction            history   \n",
              "\n",
              "   Height      Publisher  \n",
              "0     228          Wiley  \n",
              "1     235          Wiley  \n",
              "2     197        Penguin  \n",
              "3     179  HarperCollins  \n",
              "4     197        Penguin  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c37241c-3c94-4e15-9524-5b7a23dc15a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Author</th>\n",
              "      <th>Genre</th>\n",
              "      <th>SubGenre</th>\n",
              "      <th>Height</th>\n",
              "      <th>Publisher</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fundamentals of Wavelets</td>\n",
              "      <td>Goswami, Jaideva</td>\n",
              "      <td>tech</td>\n",
              "      <td>signal_processing</td>\n",
              "      <td>228</td>\n",
              "      <td>Wiley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Smart</td>\n",
              "      <td>Foreman, John</td>\n",
              "      <td>tech</td>\n",
              "      <td>data_science</td>\n",
              "      <td>235</td>\n",
              "      <td>Wiley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>God Created the Integers</td>\n",
              "      <td>Hawking, Stephen</td>\n",
              "      <td>tech</td>\n",
              "      <td>mathematics</td>\n",
              "      <td>197</td>\n",
              "      <td>Penguin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Superfreakonomics</td>\n",
              "      <td>Dubner, Stephen</td>\n",
              "      <td>science</td>\n",
              "      <td>economics</td>\n",
              "      <td>179</td>\n",
              "      <td>HarperCollins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Orientalism</td>\n",
              "      <td>Said, Edward</td>\n",
              "      <td>nonfiction</td>\n",
              "      <td>history</td>\n",
              "      <td>197</td>\n",
              "      <td>Penguin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c37241c-3c94-4e15-9524-5b7a23dc15a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c37241c-3c94-4e15-9524-5b7a23dc15a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c37241c-3c94-4e15-9524-5b7a23dc15a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n"
      ],
      "metadata": {
        "id": "7akMN1QV4U9I"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTWhprPq46z5",
        "outputId": "68f4ae65-ce27-42a2-b9f3-5ae15b61931d"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docarray in /usr/local/lib/python3.10/dist-packages (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.22.4)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray) (3.9.1)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.10.9)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (13.4.2)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.10/dist-packages (from docarray) (2.31.0.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.2->docarray) (4.6.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (2.14.0)\n",
            "Requirement already satisfied: types-urllib3 in /usr/local/lib/python3.10/dist-packages (from types-requests>=2.28.11.6->docarray) (1.26.25.13)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls = DocArrayInMemorySearch\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUYrw-nZ4hGI",
        "outputId": "1232c0a2-3342-4fd7-b17e-52c131e98402"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1/1 [00:00<00:00,  1.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please provide a list of books for Artificial Intelligence \\\n",
        "in a table in markdown and summarize each one\""
      ],
      "metadata": {
        "id": "wsdfxhdY42fZ"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query(query)"
      ],
      "metadata": {
        "id": "ZmA33zNa5hSD"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "CqGVW7Go5l3U",
        "outputId": "7ab20304-ddc0-42e0-d724-d0b2b0f41488"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n\n| Title | Author | Genre | SubGenre | Height | Publisher |\n|------|--------|-------|----------|--------|----------|\n| Introduction to Algorithms | Cormen, Thomas | tech | computer_science | 234 | MIT Press |\n| Machine Learning for Hackers | Conway, Drew | tech | data_science | 233 | O'Reilly |\n| Neural Networks | Haykin, Simon | tech | data_science | 240 |  |\n| Soft Computing & Intelligent Systems | Gupta, Madan | tech | data_science | 242 | Elsevier |\n\nIntroduction to Algorithms: Written by Thomas Cormen, this book provides an introduction to algorithms and their applications in computer science.\n\nMachine Learning for Hackers: Written by Drew Conway, this book provides an introduction to machine learning and its applications in data science.\n\nNeural Networks: Written by Simon Haykin, this book provides an introduction to neural networks and their applications in data science.\n\nSoft Computing & Intelligent Systems: Written by Madan Gupta, this book provides an introduction to soft computing and its applications in data science."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YVYMFXFD5omR"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(file_path = file)\n",
        "docs = loader.load()\n",
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pccI9jlG9Tza",
        "outputId": "b531433b-ada3-4fc9-97a9-f8d660ec6915"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Title: Fundamentals of Wavelets\\nAuthor: Goswami, Jaideva\\nGenre: tech\\nSubGenre: signal_processing\\nHeight: 228\\nPublisher: Wiley', metadata={'source': 'books_new.csv', 'row': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "0iV5hh7q9T10"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = embeddings.embed_query(\"My name is Sathish\")\n",
        "print(len(embed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8CB_sgL9T4W",
        "outputId": "a88b20ab-2052-465a-9786-f8a39e2f4f42"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ-70F7FbjJM",
        "outputId": "8f9d177c-b8de-4f5f-efc8-b8079be93cb0"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.015220541507005692, 0.0023205194156616926, 0.00045304992818273604, -0.011864017695188522, -0.026671448722481728]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = DocArrayInMemorySearch.from_documents(docs,\n",
        "                                           embeddings)\n",
        "\n",
        "query = \"Please suggest a book on deep learning\"\n",
        "docs = db.similarity_search(query)\n",
        "len(docs)\n",
        "docs[0]\n",
        "retriever = db.as_retriever()\n",
        "llm = ChatOpenAI(temperature = 0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWMpdHxM9_zL",
        "outputId": "a7e61fba-fd89-494f-d19e-3169c3884112"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1/1 [00:00<00:00,  4.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])\n",
        "response = llm.call_as_llm(f\"{qdocs} Question: Please list all your books on Deep Learning and artificial Intelligence in a table in markdown and summarize each one\")\n",
        "display(Markdown(response))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ehMQOkApEBLB",
        "outputId": "f435b444-56a4-45be-e0ee-6c8ed0e4d1b1"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Title | Author | Genre | SubGenre | Height | Publisher | Summary |\n|-------|--------|-------|----------|--------|-----------|---------|\n| Neural Networks | Haykin, Simon | tech | data_science | 240 | - | This book provides a comprehensive introduction to neural networks, covering both theory and applications. It explores the fundamental concepts and architectures of neural networks and their applications in various fields such as pattern recognition, image processing, and control systems. |\n| Machine Learning for Hackers | Conway, Drew | tech | data_science | 233 | O'Reilly | This book focuses on practical machine learning techniques and tools for hackers and data scientists. It covers topics such as data exploration, feature engineering, model building, and evaluation. It also provides hands-on examples and case studies to help readers apply machine learning in real-world scenarios. |\n| Statistical Learning Theory | Vapnik, Vladimir | tech | data_science | 228 | - | This book presents the theoretical foundations of statistical learning theory. It covers topics such as empirical risk minimization, support vector machines, and generalization bounds. It is a valuable resource for understanding the mathematical principles behind machine learning algorithms. |\n| Soft Computing & Intelligent Systems | Gupta, Madan | tech | data_science | 242 | Elsevier | This book explores the concepts and techniques of soft computing and intelligent systems. It covers topics such as fuzzy logic, neural networks, genetic algorithms, and expert systems. It provides insights into the design and implementation of intelligent systems for solving complex problems. |"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_stuff = RetrievalQA.from_chain_type(\n",
        "    llm  = llm,\n",
        "    chain_type = \"stuff\",\n",
        "    retriever = retriever,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "fwn7CRtEcgSu"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please provide a list of textbooks on deep learning and artificial intelligence in a table in markdown and summarize each one of them \"\n",
        "response = qa_stuff.run(query)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "6z-_g8GeZ9xv",
        "outputId": "c8630429-f4ea-49ce-841e-16d00b05b275"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Title                           | Author          | Genre | SubGenre      | Height | Publisher |\n|---------------------------------|-----------------|-------|---------------|--------|-----------|\n| Neural Networks                 | Haykin, Simon   | tech  | data_science  | 240    |           |\n| Statistical Learning Theory     | Vapnik, Vladimir| tech  | data_science  | 228    |           |\n| Soft Computing & Intelligent Systems | Gupta, Madan | tech  | data_science  | 242    | Elsevier  |\n| Machine Learning for Hackers    | Conway, Drew    | tech  | data_science  | 233    | O'Reilly  |\n\n**Neural Networks** by Simon Haykin is a textbook on the topic of neural networks. It covers the fundamentals of neural networks and their applications in data science. The book has a height of 240 pages.\n\n**Statistical Learning Theory** by Vladimir Vapnik is a textbook that focuses on the theory behind statistical learning. It explores the mathematical foundations of machine learning algorithms and their statistical properties. The book has a height of 228 pages.\n\n**Soft Computing & Intelligent Systems** by Madan Gupta is a textbook that covers the concepts of soft computing and intelligent systems. It discusses various techniques and algorithms used in artificial intelligence and data science. The book has a height of 242 pages and is published by Elsevier.\n\n**Machine Learning for Hackers** by Drew Conway is a textbook that caters to individuals interested in applying machine learning techniques in practical scenarios. It provides hands-on examples and case studies for learning machine learning concepts. The book has a height of 233 pages and is published by O'Reilly."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query(query, llm = llm)"
      ],
      "metadata": {
        "id": "NjJ1vvOsaCQb"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls = DocArrayInMemorySearch,\n",
        "    embedding = embeddings,\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8oIWi6-cxXB",
        "outputId": "59a3a32f-641d-411d-8da6-20062a77875f"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1/1 [00:01<00:00,  1.01s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rtr26G_Mdbh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oJaqopc3eGoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Built in LangChain tools\n",
        "!pip install -U wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKH2GGe-eGqf",
        "outputId": "958a58ab-3f2d-4a68-cb72-2483c1d95769"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=1786564a152da68191690e2b5cad77f850634ae3dd7fde7eab0a534891eb5ce1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.agent_toolkits import create_python_agent\n",
        "from langchain.agents import load_tools, initialize_agent"
      ],
      "metadata": {
        "id": "rjteu4XbeTc7"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType\n",
        "from langchain.tools.python.tool import PythonREPLTool\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature = 0)"
      ],
      "metadata": {
        "id": "jcmACiVpeiXm"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)"
      ],
      "metadata": {
        "id": "CPLsvZ29fQit"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent= initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    early_stopping_method=\"generate\",\n",
        "    verbose = True)"
      ],
      "metadata": {
        "id": "f8PXbhMrfYfD"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"Who is Prof. Gilbert Strang?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMd4i4CZf2UC",
        "outputId": "ee05424f-e3d7-4be4-b24d-6a92bb23e8cb"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.chat_models.openai:Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! {\n",
            "  \"error\": {\n",
            "    \"message\": \"The server had an error while processing your request. Sorry about that!\",\n",
            "    \"type\": \"server_error\",\n",
            "    \"param\": null,\n",
            "    \"code\": null\n",
            "  }\n",
            "}\n",
            " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Fri, 07 Jul 2023 04:05:55 GMT', 'Content-Type': 'application/json', 'Content-Length': '176', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-3.5-turbo-0613', 'openai-organization': 'user-t392jskqimacmvtioksvuk3s', 'openai-processing-ms': '314', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3500', 'x-ratelimit-limit-tokens': '90000', 'x-ratelimit-remaining-requests': '3499', 'x-ratelimit-remaining-tokens': '89655', 'x-ratelimit-reset-requests': '17ms', 'x-ratelimit-reset-tokens': '230ms', 'x-request-id': 'f49dedc4cfb9bdfff01921cc83f005b6', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7e2d363d2de9136d-ATL', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mCould not parse LLM output: Gilbert Strang is a mathematician and professor at the Massachusetts Institute of Technology (MIT). He is known for his work in linear algebra and its applications. He has authored several textbooks on the subject and has made significant contributions to the field.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: I need to use the Wikipedia tool to find information about Gilbert Strang.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: I need to use the Wikipedia tool to find information about Gilbert Strang.\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: I need to use the Wikipedia tool to find information about Gilbert Strang.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse Wikipedia output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician MIT\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra MIT\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra MIT professor\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra MIT professor books\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra MIT professor publications\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra MIT professor biography\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician linear algebra MIT professor\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to try again with a different search query.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang mathematician MIT\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mCould not parse LLM output: Could not parse LLM output: I need to use the Wikipedia tool to find information about Gilbert Strang.\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Wikipedia\",\n",
            "  \"action_input\": \"Gilbert Strang\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: Invalid or incomplete response\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Gilbert Strang is a mathematician and professor at the Massachusetts Institute of Technology (MIT). He is known for his work in linear algebra and its applications. He has authored several textbooks on the subject and has made significant contributions to the field.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Who is Gilbert Strang?',\n",
              " 'output': 'Gilbert Strang is a mathematician and professor at the Massachusetts Institute of Technology (MIT). He is known for his work in linear algebra and its applications. He has authored several textbooks on the subject and has made significant contributions to the field.'}"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHtUnR6wf7lb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}